{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO V1\n",
    "[You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640.pdf)\n",
    "## 贡献\n",
    "Yolov1是第一个One-stage的目标检测算法，将Two-stage的分类和回归问题统一为了一个回归问题。\n",
    "\n",
    "**核心思想**：将整张图片作为网络输入，直接在输出层对Bounding Box的位置和类别进行回归。\n",
    "\n",
    "**实现方法**：将图片分为$S \\times S$个栅格(grid)，如果某个Object的中心点落在了这个栅格中，就由这个栅格负责预测这个Object。每个栅格需要预测$B$个BoundingBox的位置信息$(x,y,h,w)$和置信度$(c)$，此外还要预测这个Object是每个类别的条件概率。\n",
    "\n",
    "* **(x,y,h,w)**: 分别代表的是Bounding Box的中心位置和宽高\n",
    "\n",
    "* **confidence**: 代表了所预测的box中是否存在Object，以及该Box预测准确度。公式如下：\n",
    "    $$ confidence = P_r(Object)\\times IOU_{pred}^{truth}$$\n",
    "    $P_r(Object)$表示Object是否落在这个grid里，如果grid里有Object,$P_r(Object) = 1$，否则，$P_r(Object) = 0$；\n",
    "    \n",
    "    $IOU$表示的是该BoundingBox的准确度,$pred$是预测出的BBox的区域位置，$truth$是标签区域位置，$IOU$就是求两个区域的交集比并集\n",
    "\n",
    "<div align = \"center\", style=\"height:20%;width:20%\"><img src = \"./img/IOU.png\"></img></div>\n",
    "\n",
    "* **条件概率**\n",
    "\n",
    "\n",
    "## 算法步骤\n",
    "### 1. 神经网络提取网格\n",
    "<div align = \"center\", style=\"height:50%;width:50%\"><img src = \"./img/yolov1_network.png\"></img></div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 2. NMS(非极大值抑制)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO V1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
